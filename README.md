# AddGBoost
A Gradient Boosting-Style Algorithm Based on Strong Learners

Papers are available through [Moshe Sipper's website](http://www.moshesipper.com/).

* `addgboost.py`: Code accompanying the paper, M. Sipper and J. H. Moore, "AddGBoost: A Gradient Boosting-Style Algorithm Based on Strong Learners", *Machine Learning with Applications*, 2021.<br /> 
Note: class `AddGBoost` is scikit-learn-compatible.

If you wish to cite this paper:
```
@article{sipper2002addgboost,
author = {Moshe Sipper and Jason H. Moore},
title = {AddGBoost: A gradient boosting-style algorithm based on strong learners},
journal = {Machine Learning with Applications},
volume = {7},
pages = {100243},
year = {2022},
issn = {2666-8270},
doi = {https://doi.org/10.1016/j.mlwa.2021.100243},
url = {https://www.sciencedirect.com/science/article/pii/S2666827021001225},
}
```
